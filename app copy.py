import streamlit as st
import sounddevice as sd
import numpy as np
import whisper
import tempfile
import os
import time
from scipy.io.wavfile import write

from context_adapter import adapt_transcript_context
from llm_client import chat_with_models
from static_mental_health_links import mental_health_resources
# âœ… Set API Key
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
if not OPENROUTER_API_KEY:
    st.error("âŒ Please set OPENROUTER_API_KEY in your environment.")
    st.stop()

@st.cache_resource
def load_whisper_model():
    return whisper.load_model("base")

whisper_model = load_whisper_model()

def record_audio(duration=5, fs=16000):
    st.info(f"ğŸ¤ Recording for {duration} seconds...")
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)
    sd.wait()
    return np.squeeze(audio), fs

def save_temp_wav(audio_data, sample_rate):
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
        write(tmpfile.name, sample_rate, (audio_data * 32767).astype(np.int16))
        return tmpfile.name

def transcribe(audio_path):
    result = whisper_model.transcribe(audio_path, language="ar", fp16=False)
    return result["text"]

st.set_page_config(page_title="ğŸ§  Omani Therapist Voice", layout="centered")
st.title("ğŸ§  Omani Therapist (MCP Version)")
st.caption("ğŸ™ï¸ Speak Arabic to get real-time culturally sensitive support.")

duration = st.slider("ğŸ™ï¸ Recording duration (sec)", 3, 10, 5)

if st.button("ğŸ§ Record & Respond"):
    audio, rate = record_audio(duration)
    audio_path = save_temp_wav(audio, rate)

    with st.spinner("â±ï¸ Transcribing..."):
        transcript = transcribe(audio_path)

    st.audio(audio_path, format="audio/wav")
    st.markdown(f"**ğŸ“ Transcript:** `{transcript}`")
    

    # ğŸ”„ MCP Adapter for contextual prompt modification
    adapted_transcript = adapt_transcript_context(transcript)
    if "ğŸš¨" in adapted_transcript:
        st.error("ğŸš¨ Ù‡Ø°Ù‡ Ø­Ø§Ù„Ø© Ø£Ø²Ù…Ø© Ù…Ø­ØªÙ…Ù„Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø¬Ù‡Ø© Ù…Ø®ØªØµØ© ÙÙˆØ±Ù‹Ø§.")
        st.markdown("""
        ### ğŸ“ Ø¬Ù‡Ø§Øª Ø§ØªØµØ§Ù„ Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ Ø§Ù„Ù†ÙØ³ÙŠØ© ÙÙŠ Ø³Ù„Ø·Ù†Ø© Ø¹ÙÙ…Ø§Ù†:
        - **Ù…Ø³ØªØ´ÙÙ‰ Ø§Ø¨Ù† Ø³ÙŠÙ†Ø§ Ù„Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©** â€“ Ø§Ù„Ø®Ø· Ø§Ù„Ø³Ø§Ø®Ù†: `+968-24xxxxxx`
        - **Ù…Ø±ÙƒØ² Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©** â€“ `247xxxxx`
        - **Ù…Ø±ÙƒØ² Ø´ÙØ§Ø¡ Ù„Ù„Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ©** â€“ `+968-9xxxxxxx`
        - Ø£Ùˆ Ø±Ø§Ø¬Ø¹ Ø£Ù‚Ø±Ø¨ Ù…Ø±ÙƒØ² ØµØ­ÙŠ ÙÙˆØ±Ù‹Ø§.
        """)

   

    messages = [
        {"role": "system", "content": "You are a culturally sensitive Omani therapist."},
        {"role": "user", "content": adapted_transcript}
    ]

    st.header("ğŸŒ Ù…ØµØ§Ø¯Ø± Ø¯Ø¹Ù… Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©")

    for category, links in mental_health_resources.items():
        readable = category.replace("_", " ").title()
        st.subheader(f"ğŸ”– {readable}")
        for item in links:
            st.markdown(f"- [{item['text']}]({item['url']})")

    #with st.spinner("ğŸ§  Generating Therapist Reply..."):
    #    reply, latency, model_used = chat_with_models(messages)

    
    #st.success(f"ğŸ¤– **Therapist ({model_used}):** {reply}")
    #st.markdown(f"âš¡ Latency: `{latency}s`")